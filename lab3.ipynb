{"cells":[{"cell_type":"code","execution_count":40,"metadata":{"id":"3lghA00s9EVj","executionInfo":{"status":"ok","timestamp":1702066165861,"user_tz":-180,"elapsed":337,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.nn.functional import conv2d as libConv2d\n","from torch.nn.functional import conv_transpose2d as libConv2dT\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"gcUKEMJu9EVr","executionInfo":{"status":"ok","timestamp":1702066166206,"user_tz":-180,"elapsed":11,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["# Создание тензора с исходными данными\n","input_data = torch.randn(1, 1, 2, 2)  # (batch_size, channels, height, width)\n","\n","# Создание тензора с весами (ядром) для транспонированной свертки\n","weights = torch.randn(1, 1, 2, 2)  # (out_channels, in_channels, kernel_height, kernel_width)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scoEa7Sk9EVt","executionInfo":{"status":"ok","timestamp":1702066166207,"user_tz":-180,"elapsed":12,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"27c2cc8d-46ea-43fd-dd0e-ba6d2d2d25af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 0.6835,  0.8887,  0.2105],\n","          [ 0.0112, -2.9697, -0.6390],\n","          [-0.3366,  2.2265, -1.1810]]]])"]},"metadata":{},"execution_count":42}],"source":["# Применение транспонированной свертки\n","output = libConv2dT(input_data, weights, stride=1, padding=0, dilation=1)\n","\n","output"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"bCULhrK_9EVw","executionInfo":{"status":"ok","timestamp":1702066166207,"user_tz":-180,"elapsed":11,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["stride = 1\n","padding = 0\n","dilattion = 1"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3pC8JLa9EVw","executionInfo":{"status":"ok","timestamp":1702066166207,"user_tz":-180,"elapsed":10,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"261a1dd7-a694-4ca7-b590-d7bd837e20a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[-1.5677, -0.4881],\n","          [ 1.0874, -0.6324]]]])"]},"metadata":{},"execution_count":44}],"source":["input_data"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vfAd0MvQ9EVx","executionInfo":{"status":"ok","timestamp":1702066166207,"user_tz":-180,"elapsed":8,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"367cfda3-663a-4535-e9fb-b14db9ae0037"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[-0.4360, -0.4312],\n","          [-0.3096,  1.8675]]]])"]},"metadata":{},"execution_count":45}],"source":["weights"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"ZMx8XjXR9EVy","executionInfo":{"status":"ok","timestamp":1702066166207,"user_tz":-180,"elapsed":6,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["def conv2d_transposed(\n","    matrix, in_channels, out_channels, kernel_size,\n","    stride=1, padding=0, output_padding=0, dilation=1,\n","    bias=True, padding_mode='zeros'\n","):\n","\n","    #генерация bias\n","    if bias == True:\n","      bias_val = torch.rand(out_channels)\n","    else:\n","      bias_val = torch.zeros(out_channels)\n","\n","    #padding_mode\n","    if (padding_mode != 'zeros'):\n","      raise ValueError('only \"zeros\" padding_mode in ConvTranspose2d')\n","\n","    #генерация ядра\n","    if type(kernel_size) == tuple:\n","      weights = torch.rand(in_channels, out_channels, kernel_size[0], kernel_size[1])\n","    if type(kernel_size) == int:\n","      weights = torch.rand(in_channels, out_channels, kernel_size, kernel_size)\n","\n","    res_tensor = []\n","\n","    for l in range(out_channels):\n","\n","      feature_map = torch.zeros((matrix.shape[1]-1)*stride + dilation * (kernel_size-1)+1, (matrix.shape[2]-1)*stride  + dilation * (kernel_size-1)+1 ) #генерация пустой feature-map\n","      for c in range (in_channels):\n","\n","        for i in range (0, matrix.shape[1]):  #проход по всем пикселям изображения\n","          for j in range (0, matrix.shape[2]):\n","\n","            val = matrix[c][i][j]\n","            proizv = val*weights[c][l]\n","\n","            zero_tensor = torch.zeros((weights.shape[2]-1)*dilation+1, (weights.shape[3]-1)*dilation+1)\n","\n","            for a in range (0, zero_tensor.shape[0], dilation):\n","              for b in range (0, zero_tensor.shape[1], dilation):\n","                zero_tensor[a][b] = proizv[a//dilation][b//dilation]\n","\n","            res = np.add((zero_tensor), feature_map[i*stride:i*stride+(weights.shape[2]-1)*dilation+1, j*stride:j*stride+(weights.shape[3]-1)*dilation+1])\n","            feature_map[i*stride:i*stride+(weights.shape[2]-1)*dilation+1, j*stride:j*stride+(weights.shape[3]-1)*dilation+1] = res\n","\n","\n","      res_tensor.append(np.add(feature_map, np.full((feature_map.shape), bias_val[l])))\n","\n","\n","    for t in range(len(res_tensor)):\n","      if output_padding > 0:\n","        pad_func = torch.nn.ConstantPad1d((0, output_padding, 0, output_padding), 0)\n","        res_tensor[t] = pad_func(res_tensor[t])\n","\n","      res_tensor[t] = res_tensor[t][0+padding:res_tensor[t].shape[0]-padding, 0+padding:res_tensor[t].shape[1]-padding]\n","\n","\n","    return res_tensor, weights, torch.tensor(bias_val)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"k8SeuyST9EV0","executionInfo":{"status":"ok","timestamp":1702066915574,"user_tz":-180,"elapsed":3,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["def compare(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation, bias=True, padding_mode='zeros'):\n","    myres, kernel, bias_val = conv2d_transposed(\n","        tensor,\n","        in_channels=in_channels, out_channels=out_channels,\n","        kernel_size=kernel_size, stride=stride,\n","        padding=padding, output_padding=output_padding,\n","        dilation=dilation, bias=bias,\n","        padding_mode=padding_mode,\n","        )\n","    torchFunction = torch.nn.ConvTranspose2d(\n","        in_channels=in_channels, out_channels=out_channels,\n","        kernel_size=kernel_size, stride=stride,\n","        padding=padding, output_padding=output_padding,\n","        dilation=dilation, bias=bias,\n","        padding_mode=padding_mode,\n","        )\n","    torchFunction.weight.data = kernel\n","    torchFunction.bias.data = bias_val\n","\n","    result = str(np.round([tensor.tolist() for tensor in myres],2))\n","    torch_res = str(np.round(torchFunction(tensor).data.numpy(),2))\n","    return result==torch_res"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwNHtrEk9EV1","executionInfo":{"status":"ok","timestamp":1702066926975,"user_tz":-180,"elapsed":339,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"a6b15914-9f3b-4f61-bd3b-f104247a3cb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["tensor1 = torch.rand(8, 5, 6)\n","print(compare(tensor1, in_channels=8, out_channels=2, kernel_size=3, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros'))"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KctVQlZG9EV2","executionInfo":{"status":"ok","timestamp":1702066167245,"user_tz":-180,"elapsed":690,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"20119070-fd8a-4eaf-c617-d13d7ce75384"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":49}],"source":["tensor2 = torch.rand(3, 28, 28)\n","print(compare(tensor2, in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0, output_padding=0, dilation=3, bias=True, padding_mode='zeros'))"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks8KcYR79EV2","executionInfo":{"status":"ok","timestamp":1702066167245,"user_tz":-180,"elapsed":8,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"970a97ec-082f-450a-e481-5323d0ae0ffd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":50}],"source":["tensor3 = torch.rand(5, 6, 6)\n","print(compare(tensor3, in_channels=5, out_channels=1, kernel_size=3, stride=3, padding=5, output_padding=2, dilation=1, bias=True, padding_mode='zeros'))"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSNnn8DM9EV3","executionInfo":{"status":"ok","timestamp":1702067043015,"user_tz":-180,"elapsed":6,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"2b29e3f5-e584-435f-fb7b-2ee8c4e963a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["tensor4 = torch.rand(1, 1, 1)\n","print(compare(tensor4, in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros'))"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"LCvwKIdB9EV3","executionInfo":{"status":"ok","timestamp":1702066167245,"user_tz":-180,"elapsed":4,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["def cooler_transpconv2d(\n","  input, in_channels, out_channels, kernel_size,\n","  transp_stride=1, padding=0, dilation=1, bias=True,\n","  padding_mode='zeros'\n","):\n","  stride = 1\n","\n","  #добавление отступов и padding в входной матрице\n","  pad = kernel_size - 1\n","  result_input = []\n","  for matr in input:\n","    zero_tensor = np.zeros((((matr.shape[0]-1)*(transp_stride)+1), ((matr.shape[1]-1)*(transp_stride)+1)))\n","    for a in range (0, zero_tensor.shape[0], transp_stride):\n","      for b in range (0, zero_tensor.shape[1], transp_stride):\n","        zero_tensor[a][b] = matr[a//(transp_stride)][b//(transp_stride)]\n","\n","    pad_matr = np.pad(zero_tensor, pad_width=pad, mode='constant')\n","    result_input.append(pad_matr)\n","  input = torch.tensor(result_input)\n","  #генерация bias\n","  if bias == True:\n","    bias_val = torch.rand(out_channels)\n","  else:\n","    bias_val = torch.zeros(out_channels)\n","\n","  #padding_mode\n","  if (padding_mode == 'zeros'):\n","    pad = torch.nn.ZeroPad2d(padding)\n","    input = pad(input)\n","  if (padding_mode == 'reflect'):\n","    pad = torch.nn.ReflectionPad2d(padding)\n","    input = pad(input)\n","  if (padding_mode == 'replicate'):\n","    pad = torch.nn.ReplicationPad2d(padding)\n","    input = pad(input)\n","  if (padding_mode == 'circular'):\n","    pad = torch.nn.CircularPad2d(padding)\n","    input = pad(input)\n","\n","  #генерация ядра\n","  weights = np.array(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n","\n","  #инвертирование ядра для ConvTranspose2d\n","  weights_for_transpose = []\n","  for j in range(out_channels):\n","    weights_in = []\n","    for i in range(in_channels):\n","      weights_in.append(np.flip(np.array(weights[j][i])))\n","    weights_for_transpose.append(weights_in)\n","\n","  weights_for_transpose = torch.tensor(weights_for_transpose)\n","  weights_for_transpose = weights_for_transpose.reshape(in_channels, out_channels, kernel_size, kernel_size)\n","\n","\n","\n","  res_tensor = []\n","  for l in range(out_channels):\n","    feature_map = np.array([]) #генерация пустой feature-map\n","    for i in range (0, input.shape[1]-((weights.shape[2]-1)*dilation+1)+1, stride): #(weights.size - 1)*dilation + 1 при delation\n","      for j in range (0, input.shape[2]-((weights.shape[3]-1)*dilation+1)+1, stride):\n","        summa = 0\n","        for c in range (in_channels):\n","          val = input[c][i:i+(weights.shape[2]-1)*dilation+1:dilation, j:j+(weights.shape[3]-1)*dilation+1:dilation]\n","          mini_sum = (val*weights[l][c]).sum()\n","          summa = summa + mini_sum\n","        feature_map = np.append(feature_map, float(summa + bias_val[l])) #bias\n","    res_tensor.append(feature_map.reshape((input.shape[1]-((weights.shape[2]-1)*dilation+1))//stride+1, (input.shape[2]-((weights.shape[3]-1)*dilation+1))//stride+1))\n","\n","\n","  return np.array(res_tensor), torch.tensor(np.array(weights_for_transpose)), torch.tensor(np.array(bias_val))"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"Wdx7_p2g9EV4","executionInfo":{"status":"ok","timestamp":1702066167246,"user_tz":-180,"elapsed":5,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}}},"outputs":[],"source":["tensor1 = torch.rand(3, 5, 6)\n","tensor2 = torch.rand(1, 28, 28)\n","tensor3 = torch.rand(7, 10, 10)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4Px-0Zn9EV4","executionInfo":{"status":"ok","timestamp":1702066167571,"user_tz":-180,"elapsed":329,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"4e2f7fed-e29a-43f6-8650-2c2fb9535131"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":54}],"source":["result, kernel, bias_val = cooler_transpconv2d(tensor1,in_channels=3, out_channels=1, kernel_size=3, transp_stride=2, bias=True,)\n","torchFunction = torch.nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=3, stride=2, bias=True,)\n","torchFunction.weight.data = kernel\n","torchFunction.bias.data = bias_val\n","myResult = str(np.round(result, 2))\n","torchResult = str(np.round(np.array(torchFunction(tensor1).data), 2))\n","torchResult == myResult"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCq3blrx9EV4","executionInfo":{"status":"ok","timestamp":1702066169256,"user_tz":-180,"elapsed":1687,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"0997748d-7b48-4c9b-af24-3c7dee7b40ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":55}],"source":["result, kernel, bias_val = cooler_transpconv2d(tensor2,in_channels=1, out_channels=2, kernel_size=4, transp_stride=3, bias=True)\n","torchFunction = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=4, stride=3, bias=True)\n","torchFunction.weight.data = kernel\n","torchFunction.bias.data = bias_val\n","myResult = str(np.round(result, 2))\n","torchResult = str(np.round(np.array(torchFunction(tensor2).data), 2))\n","torchResult == myResult"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCzd9zqA9EV5","executionInfo":{"status":"ok","timestamp":1702066170800,"user_tz":-180,"elapsed":1548,"user":{"displayName":"Adlisse","userId":"09888939323989321551"}},"outputId":"ec766b50-c012-421a-dcf2-d719a44f1895"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":56}],"source":["result, kernel, bias_val = cooler_transpconv2d(tensor3, in_channels=7, out_channels=1, kernel_size=3, transp_stride=5, bias=True)\n","torchFunction = torch.nn.ConvTranspose2d(in_channels=7, out_channels=1, kernel_size=3, stride=5, bias=True)\n","torchFunction.weight.data = kernel\n","torchFunction.bias.data = bias_val\n","myResult = str(np.round(result, 2))\n","torchResult = str(np.round(np.array(torchFunction(tensor3).data), 2))\n","torchResult == myResult"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}